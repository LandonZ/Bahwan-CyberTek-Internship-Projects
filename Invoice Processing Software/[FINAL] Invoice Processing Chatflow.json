{
  "nodes": [
    {
      "id": "bufferMemory_0",
      "position": {
        "x": 630.8253653321427,
        "y": 695.0563100052025
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 253,
      "selected": false,
      "positionAbsolute": {
        "x": 630.8253653321427,
        "y": 695.0563100052025
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": 998.4921500603432,
        "y": 618.2768455041257
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 6,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o",
          "temperature": "0.4",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": true,
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": 998.4921500603432,
        "y": 618.2768455041257
      },
      "dragging": false
    },
    {
      "id": "conversationalAgent_0",
      "position": {
        "x": 1015.88822213703,
        "y": 45.588207863773846
      },
      "type": "customNode",
      "data": {
        "id": "conversationalAgent_0",
        "label": "Conversational Agent",
        "version": 3,
        "name": "conversationalAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "rows": 4,
            "default": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
            "optional": true,
            "additionalParams": true,
            "id": "conversationalAgent_0-input-systemMessage-string"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "conversationalAgent_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Allowed Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "conversationalAgent_0-input-tools-Tool"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "conversationalAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{chainTool_1.data.instance}}"
          ],
          "model": "{{chatOpenAI_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "systemMessage": "You are a helper for all actions regarding invoice image uploads, such as processing the invoice for specific needed details and uploading these invoice details onto Airtable.\n\nWhen you see an invoice image, I want you to immediately process the image and give me the 3 necessary fields (name, price (總計), and buyer (買方). Then, I want you to IMMEDIATELY UPLOAD THESE DETAILS AS A RECORD ONTO AIRTABLE using the one tool provided to you.\n\nUse your Vision capabilities to process the invoice and retrieve the 3 fields I need.\n\nWhen uploading the invoice details onto Airtable, remember to use the name, price, and buyer of the invoice image upload.\n\nThen, output a summary of the name, price, and buyer from the invoice image upload, where all fields (name, price, and buyer) are on a different row in bullet points, like a bullet point list.",
          "inputModeration": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalAgent_0-output-conversationalAgent-AgentExecutor|BaseChain|Runnable",
            "name": "conversationalAgent",
            "label": "AgentExecutor",
            "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 435,
      "selected": false,
      "positionAbsolute": {
        "x": 1015.88822213703,
        "y": 45.588207863773846
      },
      "dragging": false
    },
    {
      "id": "chainTool_1",
      "position": {
        "x": 569.5919004239228,
        "y": -44.945455185839535
      },
      "type": "customNode",
      "data": {
        "id": "chainTool_1",
        "label": "Chain Tool",
        "version": 1,
        "name": "chainTool",
        "type": "ChainTool",
        "baseClasses": [
          "ChainTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a chain as allowed tool for agent",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "name",
            "type": "string",
            "placeholder": "state-of-union-qa",
            "id": "chainTool_1-input-name-string"
          },
          {
            "label": "Chain Description",
            "name": "description",
            "type": "string",
            "rows": 3,
            "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
            "id": "chainTool_1-input-description-string"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "type": "boolean",
            "optional": true,
            "id": "chainTool_1-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Base Chain",
            "name": "baseChain",
            "type": "BaseChain",
            "id": "chainTool_1-input-baseChain-BaseChain"
          }
        ],
        "inputs": {
          "name": "uploading invoice",
          "description": "Use this tool when you need to upload an invoice.",
          "returnDirect": "",
          "baseChain": "{{postApiChain_1.data.instance}}"
        },
        "outputAnchors": [
          {
            "id": "chainTool_1-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "chainTool",
            "label": "ChainTool",
            "description": "Use a chain as allowed tool for agent",
            "type": "ChainTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 603,
      "selected": false,
      "positionAbsolute": {
        "x": 569.5919004239228,
        "y": -44.945455185839535
      },
      "dragging": false
    },
    {
      "id": "postApiChain_0",
      "position": {
        "x": -58.48937260723261,
        "y": 660.5423139981666
      },
      "type": "customNode",
      "data": {
        "id": "postApiChain_0",
        "label": "POST API Chain",
        "version": 1,
        "name": "postApiChain",
        "type": "POSTApiChain",
        "baseClasses": [
          "POSTApiChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against POST API",
        "inputParams": [
          {
            "label": "API Documentation",
            "name": "apiDocs",
            "type": "string",
            "description": "Description of how API works. Please refer to more <a target=\"_blank\" href=\"https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/api/open_meteo_docs.py\">examples</a>",
            "rows": 4,
            "id": "postApiChain_0-input-apiDocs-string"
          },
          {
            "label": "Headers",
            "name": "headers",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "postApiChain_0-input-headers-json"
          },
          {
            "label": "URL Prompt",
            "name": "urlPrompt",
            "type": "string",
            "description": "Prompt used to tell LLMs how to construct the URL. Must contains {api_docs} and {question}",
            "default": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string:",
            "rows": 4,
            "additionalParams": true,
            "id": "postApiChain_0-input-urlPrompt-string"
          },
          {
            "label": "Answer Prompt",
            "name": "ansPrompt",
            "type": "string",
            "description": "Prompt used to tell LLMs how to return the API response. Must contains {api_response}, {api_url}, and {question}",
            "default": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string: {api_url_body}\n\nHere is the response from the API:\n\n{api_response}\n\nSummarize this response to answer the original question.\n\nSummary:",
            "rows": 4,
            "additionalParams": true,
            "id": "postApiChain_0-input-ansPrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "postApiChain_0-input-model-BaseLanguageModel"
          }
        ],
        "inputs": {
          "model": "",
          "apiDocs": "Create records\nPOST\nhttps://api.airtable.com/v0/REDACTED\nAPI TOKEN YOU NEED TO USE FOR AUTHENTICATION: REDACTED\n\nAuthentication example:\nheaders: {\n  \"Authorization\": \"Bearer REDACTED\",\n  \"Content-Type\": \"application/json\"\n}\n\nCreates multiple records. Note that table names and table ids can be used interchangeably. We recommend using table IDs so you don't need to modify your API request when your table name changes.\n\nYour request body should include an array of up to 10 record objects. Each of these objects should have one key whose value is an inner object containing your record's cell values, keyed by either field name or field id.\n\nReturns a unique array of the newly created record ids if the call succeeds.\n\nYou can also include a single record object at the top level.\n\nRequirements\nAuthentication\tPersonal access token, OAuth integration\nScope\tdata.records:write\nUser role\t\nBase editor\n\nBilling plans\tAll plans\nPath parameters\nbaseId\nstring\ntableIdOrName\nstring\nRequest body\nfields\noptional<the below object>\nCreate a single record\n\nkey: string\tCell value\nrecords\noptional<array of the below object>\nCreate multiple records\n\nPass in multiple records to create multiple in one request\n\nfields\nobject\nkey: string\tCell value\nreturnFieldsByFieldId\noptional<boolean>\nAn optional boolean value that lets you return field objects keyed by the field id.\n\nThis defaults to false, which returns field objects where the key is the field name.\n\ntypecast\noptional<boolean>\nThe Airtable API will perform best-effort automatic data conversion from string values if the typecast parameter is passed in. Automatic conversion is disabled by default to ensure data integrity, but it may be helpful for integrating with 3rd party data sources.\n\nResponse format\nany of the below objects\nrecords\narray of the below object\nid\nstring\nRecord ID\n\ncreatedTime\nstring\nA date timestamp in the ISO format, eg:\"2018-01-01T00:00:00.000Z\"\n\nfields\nobject\nCell values are keyed by either field name or field ID (conditioned on returnFieldsByFieldId).\n\nSee Cell Values for more information on cell value response types.\n\nkey: string\tCell value\nid\nstring\nRecord ID\n\ncreatedTime\nstring\nA date timestamp in the ISO format, eg:\"2018-01-01T00:00:00.000Z\"\n\nfields\nobject\nCell values are keyed by either field name or field ID (conditioned on returnFieldsByFieldId).\n\nSee Cell Values for more information on cell value response types.\n\nkey: string\tCell value\n\n\nEXAMPLE JSON OBJECT BELOW:\n{\n  url: \"https://api.airtable.com/v0/REDACTED/REDACTED\",\n  method: \"POST\",\n  headers: {\n  \"Authorization\": \"Bearer REDACTED\",\n  \"Content-Type\": \"application/json\"\n  },\n  body: {\n    \"records\": [\n      {\n        \"fields\": {\n          \"name\": \"ATT 4 FUN\",\n          \"price\": 2800,\n          \"buyer\": 234238\n        }\n      }\n    ]\n  } \n}\n\n200 – RESPONSE\n{\n  \"createdTime\": \"2022-09-12T21:03:48.000Z\",\n  \"fields\": {\n      \"name\": \"ATT 4 FUN\",\n      \"price\": 2800,\n      \"buyer\": 234238\n  },\n  \"id\": \"rec560UJdUtocSouk\"\n}\n",
          "headers": "",
          "urlPrompt": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json object with these keys: url, method, headers, and body. These keys ARE NOT STRINGS.\nThe value of url should be a string, which is the API url to call for answering the user question.\nThe value of method should always be \"POST\".\nThe value of headers should be a dictionary of 2 key-value pairs: \n\"Authorization\": \"Bearer YOUR_API_KEY\" where YOUR_API_KEY is replaced by the actual token, and,\n\"Content-Type\": \"application/json\"\nThe value of body should be a dictionary of 1 key-value pair called \"records\" that has a body of an array. Inside the array, there should be 1 value which is a dictionary of 1 key-value pair called \"fields\" that has a body of a dictionary. Inside this dictionary should be key-value pairs you want to POST to the url as a JSON body.\n\nWhere the dictionary linked to \"fields\" has the 3 key-value pairs of \"name\", \"price\", and \"buyer\".\n\nYou should build the json object in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson object:",
          "ansPrompt": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json object with these keys: url, method, headers, and body. These keys ARE NOT STRINGS.\nThe value of url should be a string, which is the API url to call for answering the user question.\nThe value of method should always be \"POST\".\nThe value of headers should be a dictionary of 2 key-value pairs: \n\"Authorization\": \"Bearer YOUR_API_KEY\" where YOUR_API_KEY is replaced by the actual token, and,\n\"Content-Type\": \"application/json\"\nThe value of body should be a dictionary of 1 key-value pair called \"records\" that has a body of an array. Inside the array, there should be 1 value which is a dictionary of 1 key-value pair called \"fields\" that has a body of a dictionary. Inside this dictionary should be key-value pairs you want to POST to the url as a JSON body.\n\nWhere the dictionary linked to \"fields\" has the 3 key-value pairs of \"name\", \"price\", and \"buyer\".\n\nYou should build the json object in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson object: {api_url_body}\n\nHere is the response from the API:\n\n{api_response}\n\nSummarize this response to answer the original question.\n\nSummary:"
        },
        "outputAnchors": [
          {
            "id": "postApiChain_0-output-postApiChain-POSTApiChain|BaseChain|Runnable",
            "name": "postApiChain",
            "label": "POSTApiChain",
            "description": "Chain to run queries against POST API",
            "type": "POSTApiChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 460,
      "selected": false,
      "positionAbsolute": {
        "x": -58.48937260723261,
        "y": 660.5423139981666
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_2",
      "position": {
        "x": -231.50720615114344,
        "y": -164.5712563404341
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_2",
        "label": "ChatOpenAI",
        "version": 6,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_2-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_2-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_2-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_2-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_2-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo",
          "temperature": "0.4",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": -231.50720615114344,
        "y": -164.5712563404341
      },
      "dragging": false
    },
    {
      "id": "postApiChain_1",
      "position": {
        "x": 179.76244042756082,
        "y": 13.29823805133691
      },
      "type": "customNode",
      "data": {
        "id": "postApiChain_1",
        "label": "POST API Chain",
        "version": 1,
        "name": "postApiChain",
        "type": "POSTApiChain",
        "baseClasses": [
          "POSTApiChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against POST API",
        "inputParams": [
          {
            "label": "API Documentation",
            "name": "apiDocs",
            "type": "string",
            "description": "Description of how API works. Please refer to more <a target=\"_blank\" href=\"https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/api/open_meteo_docs.py\">examples</a>",
            "rows": 4,
            "id": "postApiChain_1-input-apiDocs-string"
          },
          {
            "label": "Headers",
            "name": "headers",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "postApiChain_1-input-headers-json"
          },
          {
            "label": "URL Prompt",
            "name": "urlPrompt",
            "type": "string",
            "description": "Prompt used to tell LLMs how to construct the URL. Must contains {api_docs} and {question}",
            "default": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string:",
            "rows": 4,
            "additionalParams": true,
            "id": "postApiChain_1-input-urlPrompt-string"
          },
          {
            "label": "Answer Prompt",
            "name": "ansPrompt",
            "type": "string",
            "description": "Prompt used to tell LLMs how to return the API response. Must contains {api_response}, {api_url}, and {question}",
            "default": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string: {api_url_body}\n\nHere is the response from the API:\n\n{api_response}\n\nSummarize this response to answer the original question.\n\nSummary:",
            "rows": 4,
            "additionalParams": true,
            "id": "postApiChain_1-input-ansPrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "postApiChain_1-input-model-BaseLanguageModel"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_2.data.instance}}",
          "apiDocs": "API documentation:\nEndpoint: https://eo1sdshg0bstdex.m.pipedream.net\n\nThis API is for creating a record of an invoice on Airtable\n\nbody table:\nname | string | name of the invoice | required\nprice | integer | price of what was bought in the invoice | required\nbuyer | integer | buyer id of the invoice | required\n\nResponse schema (string):\nresult | string",
          "headers": "",
          "urlPrompt": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string:",
          "ansPrompt": "You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate a json string with two keys: \"url\" and \"data\".\nThe value of \"url\" should be a string, which is the API url to call for answering the user question.\nThe value of \"data\" should be a dictionary of key-value pairs you want to POST to the url as a JSON body.\nBe careful to always use double quotes for strings in the json string.\nYou should build the json string in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\njson string: {api_url_body}\n\nHere is the response from the API:\n\n{api_response}\n\nSummarize this response to answer the original question.\n\nSummary:"
        },
        "outputAnchors": [
          {
            "id": "postApiChain_1-output-postApiChain-POSTApiChain|BaseChain|Runnable",
            "name": "postApiChain",
            "label": "POSTApiChain",
            "description": "Chain to run queries against POST API",
            "type": "POSTApiChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 460,
      "selected": false,
      "positionAbsolute": {
        "x": 179.76244042756082,
        "y": 13.29823805133691
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalAgent_0-conversationalAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationalAgent_0-conversationalAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "chainTool_1",
      "sourceHandle": "chainTool_1-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "chainTool_1-chainTool_1-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable-conversationalAgent_0-conversationalAgent_0-input-tools-Tool"
    },
    {
      "source": "postApiChain_1",
      "sourceHandle": "postApiChain_1-output-postApiChain-POSTApiChain|BaseChain|Runnable",
      "target": "chainTool_1",
      "targetHandle": "chainTool_1-input-baseChain-BaseChain",
      "type": "buttonedge",
      "id": "postApiChain_1-postApiChain_1-output-postApiChain-POSTApiChain|BaseChain|Runnable-chainTool_1-chainTool_1-input-baseChain-BaseChain"
    },
    {
      "source": "chatOpenAI_2",
      "sourceHandle": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "postApiChain_1",
      "targetHandle": "postApiChain_1-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatOpenAI_2-chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-postApiChain_1-postApiChain_1-input-model-BaseLanguageModel"
    }
  ]
}